# This configure based on Example Static Config.
# See https://grafana.com/docs/loki/latest/clients/promtail/configuration/#example-static-config for detail.

# Configures the server for Promtail.
server:

  # HTTP server listen port (0 means random port)
  http_listen_port: 9080
  grpc_listen_port: 0

# Describes how Promtail connects to multiple instances
# of Grafana Loki, sending logs to each.
# WARNING: If one of the remote Loki servers fails to respond or responds
# with any error which is retryable, this will impact sending logs to any
# other configured remote Loki servers.  Sending is done on a single thread!
# It is generally recommended to run multiple Promtail clients in parallel
# if you want to send to multiple remote Loki instances.
clients:

  # The URL where Loki is listening, denoted in Loki as http_listen_address and
  # http_listen_port. If Loki is running in microservices mode, this is the HTTP
  # URL for the Distributor. Path to the push API needs to be included.
  # Example: http://example.com:3100/loki/api/v1/push
  - url: http://127.0.0.1:3100/loki/api/v1/push

# Describes how to save read file offsets to disk
positions:

  # Location of positions file
  filename: ./positions.yaml
  
  # Whether to ignore & later overwrite positions files that are corrupted
  ignore_invalid_yaml: true

# The scrape_configs block configures how Promtail can scrape logs from
# a series of targets using a specified discovery method
scrape_configs:

  # Name to identify this scrape config in the Promtail UI.
  - job_name: loki_log

    # Static targets to scrape.
    static_configs:

      # Configures the discovery to look on the current machine.
      # This is required by the prometheus service discovery code but doesn't
      # really apply to Promtail which can ONLY look at files on the local machine
      # As such it should only have the value of localhost, OR it can be excluded
      # entirely and a default value of localhost will be applied by Promtail.
      - targets:
          - localhost

        # Defines a file to scrape and an optional set of additional labels to apply to
        # all streams defined by the files from __path__.
        labels:

          # A `job` label is fairly standard in prometheus and useful for linking metrics and logs.
          job: varlogs

          # A `host` label will help identify logs from this machine vs others
          host: 127.0.0.1

          # The path to load logs from. Can use glob patterns (e.g., /var/log/*.log).
          __path__: ./log/*.log

          # Refresh interval to re-read the files.
          refresh_interval: 1m


    # Pipeline stages are used to transform log entries and their labels.
    # The pipeline is executed after the discovery process finishes.
    # The pipeline_stages object consists of a list of stages which correspond to the items listed below.
    #
    # In most cases, you extract data from logs with regex or json stages.
    # The extracted data is transformed into a temporary map object.
    # The data can then be used by Promtail e.g. as values for labels or as an output.
    # Additionally any other stage aside from docker and cri can access the extracted data.
    pipeline_stages:

      # The match stage conditionally executes a set of stages
      # when a log entry matches a configurable LogQL stream selector.
      - match:

          # LogQL stream selector.
          selector: '{job="varlogs"}'

          # Nested set of pipeline stages only if the selector
          # matches the labels of the log entries:
          stages:

            # The regex stage is a parsing stage that parses a log line using a regular expression.
            # Named capture groups in the regex support adding data into the extracted map.
            - regex:
 
                # Name from extracted data to parse. If empty, uses the log message.
                source: filename

                # The RE2 regular expression. Each capture group must be named.
                expression: '^(?P<log_dir>.*)\/(?P<log_filename>[^\/]*)$'

            - regex:
                expression: '^(?P<level>F|E|W|I|D)(?P<yyyy>\S{4})(?P<mm>\S{2})(?P<dd>\S{2}) (?P<time>\S+?) (?P<pid>\S+?) (?P<filename>\S+?):(?P<lineno>\S+?)] (?P<content>.*)$'

            # The template stage is a transform stage that lets use manipulate the values
            # in the extracted map using Goâ€™s template syntax.
            #
            # The template stage is primarily useful for manipulating data from other stages
            # before setting them as labels, such as to replace spaces with underscores
            # or converting an uppercase string into a lowercase one.
            # `template` can also be used to construct messages with multiple keys.
            #
            # The template stage can also create new keys in the extracted map.
            - template:
                source: timestamp

                # Go template string to use. In additional to normal template
                # functions, ToLower, ToUpper, Replace, Trim, TrimLeft, TrimRight,
                # TrimPrefix, TrimSuffix, and TrimSpace are available as functions.
                template: "{{ .yyyy }}-{{ .mm }}-{{ .dd }}T{{ .time }}000+08:00"

            # The timestamp stage is an action stage that can change the timestamp of a log line
            # before it is sent to Loki. When a timestamp stage is not present,
            # the timestamp of a log line defaults to the time when the log entry is scraped.
            - timestamp:
                source: timestamp

                # Determines how to parse the time string. Can use
                # pre-defined formats by name: [ANSIC UnixDate RubyDate RFC822
                # RFC822Z RFC850 RFC1123 RFC1123Z RFC3339 RFC3339Nano Unix
                # UnixMs UnixUs UnixNs].
                format: RFC3339Nano

            # The labels stage is an action stage that takes data from the extracted map
            # and modifies the label set that is sent to Loki with the log entry.
            #
            # Key is REQUIRED and the name for the label that will be created.
            # Value is optional and will be the name from extracted data whose value
            # will be used for the value of the label. If empty, the value will be
            # inferred to be the same as the key.
            - labels:
                log_dir:
                log_filename:
                level:
                filename:
                lineno:
                timestamp:

            # The output stage is an action stage that takes data from the extracted map
            # and changes the log line that will be sent to Loki.
            - output:
                source: content


# Configures global limits for this instance of Promtail
# [limits_config: <limits_config>]

# Configures how tailed targets will be watched.
# [target_config: <target_config>]

# Configures additional promtail configurations.
# [options: <options_config>]

# Configures tracing support
# [tracing: <tracing_config>]
